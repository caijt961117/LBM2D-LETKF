#! /bin/bash -ue
#PJM -N v2.4.2_timer_culb2d
#PJM -L node=1
#PJM -L rscgrp=regular-a
#PJM -L elapse=0:10:0
#PJM -s
#PJM -j
#PJM -o log/timer_v2.4.2.txt
#PJM -g jh220030a
#PJM --mpi proc=4

# modules
. /etc/profile.d/modules.sh 
module purge 
module load gcc/8.3.1
module load cuda/11.2
module load ompi-cuda/4.1.1-11.2
module load hdf5/1.12.0

module list 2>&1 

# environmental variables
# default: export UCX_MEMTYPE_CACHE=n; export UCX_IB_GPU_DIRECT_RDMA=no
export UCX_MEMTYPE_CACHE=n
export UCX_IB_GPU_DIRECT_RDMA=no
export OMP_NUM_THREADS=6

env

run () {
N=$1
p=$2
beta=$3
daprune=10
d=timer_v2.4.3
iop=$daprune

echo ======================================================
echo start run N=$N daprune=$daprune xyprune=$p beta=$beta
echo ======================================================


#RESULT_DIR=result/$d/xyprune$p
RESULT_DIR=result/$d/ens${N}_xyprune${p}
mkdir -p $RESULT_DIR

# func
run_mpirun() {
    #n=$PJM_MPI_PROC
    n=$1
    mpiexec -machinefile $PJM_O_NODEINF -np $n -npernode 8 run/a.out
    2>&1
}

make clean resultclean

## obs
make clean 
make -j TEST=OBSERVE DA_XYPRUNE=$p IOPRUNE=$iop DAPRUNE=$daprune
run_mpirun 1

## letkf
make clean
make -j TEST=DA_LETKF DA_XYPRUNE=$p DAPRUNE=$daprune IOPRUNE=$iop LETKF_COVINF=$beta
run_mpirun $N
mv io/*.csv $RESULT_DIR/
}

# pointwise LETKF
run 4  1 1
